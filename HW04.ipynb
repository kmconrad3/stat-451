{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8163daf4",
   "metadata": {},
   "source": [
    "### HW04: Practice with feature engineering, splitting data, and fitting and regularizing linear models\n",
    "\n",
    "Kara Conrad, 9082326472"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdedd9b",
   "metadata": {},
   "source": [
    "### Hello Students:\n",
    "\n",
    "- Start by downloading HW04.ipynb from this folder. Then develop it into your solution.\n",
    "- Write code where you see \"... your code here ...\" below.\n",
    "  (You are welcome to use more than one cell.)\n",
    "- If you have questions, please ask them in class, office hours, or piazza. Our TA\n",
    "  and I are very happy to help with the programming (provided you start early\n",
    "  enough, and provided we are not helping so much that we undermine your learning).\n",
    "- When you are done, run these Notebook commands:\n",
    "  - Shift-L (once, so that line numbers are visible)\n",
    "  - Kernel > Restart and Run All (run all cells from scratch)\n",
    "  - Esc S (save)\n",
    "  - File > Download as > HTML\n",
    "- Turn in:\n",
    "  - HW04.ipynb to Canvas's HW04.ipynb assignment\n",
    "  - HW04.html to Canvas's HW04.html assignment\n",
    "  - As a check, download your files from Canvas to a new 'junk' folder. Try 'Kernel > Restart\n",
    "  and Run All' on the '.ipynb' file to make sure it works. Glance through the '.html' file.\n",
    "- Turn in partial solutions to Canvas before the deadline. e.g. Turn in part 1,\n",
    "  then parts 1 and 2, then your whole solution. That way we can award partial credit\n",
    "  even if you miss the deadline. We will grade your last submission before the deadline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6a87448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90946b9",
   "metadata": {},
   "source": [
    "## 1. Feature engineering (one-hot encoding and data imputation)\n",
    "\n",
    "(Note: This paragraph is not instructions but rather is to communicate context for this exercise. We use the same Titanic data we used in HW02:\n",
    "- There we used `df.dropna()` to drop any observations with missing values; here we use data imputation instead.\n",
    "- There we manually did one-hot encoding of the categorical `Sex` column by making a `Female` column; here we do the same one-hot encoding with the help of pandas's `df.join(pd.get_dummies())`.\n",
    "- There we used a decision tree; here we use $k$-NN.\n",
    "\n",
    "We evaluate how these strategies can improve model performance by allowing us to use columns with categorical or missing data.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa128a8c",
   "metadata": {},
   "source": [
    "### 1a. Read the data from [http://www.stat.wisc.edu/~jgillett/451/data/kaggle_titanic_train.csv](http://www.stat.wisc.edu/~jgillett/451/data/kaggle_titanic_train.csv).\n",
    "- Retain only these columns: Survived, Pclass, Sex, Age, SibSp, Parch.\n",
    "- Display the first 7 rows.\n",
    "\n",
    "These data are described at [https://www.kaggle.com/competitions/titanic/data](https://www.kaggle.com/competitions/titanic/data) (click on the small down-arrow to see the \"Data Dictionary\"), which is where they are from.\n",
    "- Read that \"Data Dictionary\" paragraph (with your eyes, not python) so you understand what each column represents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "700852b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch\n",
       "0         0       3    male  22.0      1      0\n",
       "1         1       1  female  38.0      1      0\n",
       "2         1       3  female  26.0      0      0\n",
       "3         1       1  female  35.0      1      0\n",
       "4         0       3    male  35.0      0      0\n",
       "5         0       3    male   NaN      0      0\n",
       "6         0       1    male  54.0      0      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"http://www.stat.wisc.edu/~jgillett/451/data/kaggle_titanic_train.csv\")[[\"Survived\", \"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\"]]\n",
    "df.head(n=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fda2ee",
   "metadata": {},
   "source": [
    "### 1b. Try to train a $k$NN model to predict $y=$ 'Survived' from $X=$ these features: 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch'.\n",
    "- Use $k = 3$ and the (default) euclidean metric.\n",
    "- Notice at the bottom of the error message that it fails with the error \"ValueError: could not convert string to float: 'male'\".\n",
    "- Comment out your .fit() line so the cell can run without error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faf87ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "y=df[\"Survived\"]\n",
    "X=df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch']]\n",
    "#kNN.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eea90e",
   "metadata": {},
   "source": [
    "### 1c. Try to train again, this time without the 'Sex' feature.\n",
    "- Notice that it fails because \"Input contains NaN\".\n",
    "- Comment out your .fit() line so the cell can run without error.\n",
    "- Run `X.isna().any()` (where X is the name of your DataFrame of features) to see that\n",
    "  the 'Age' feature has missing values. (You can see the first missing value in\n",
    "  the sixth row that you displayed above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4032cc0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass    False\n",
       "Age        True\n",
       "SibSp     False\n",
       "Parch     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df[['Pclass', 'Age', 'SibSp', 'Parch']]\n",
    "#kNN.fit(X, y)\n",
    "X.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b103b9",
   "metadata": {},
   "source": [
    "### 1d. Train without the 'Sex' and 'Age' features.\n",
    "- Report accuracy on the training data with a line of the form\n",
    "  `Accuracy on training data is  0.500` (0.500 may not be correct)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e626bdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data is 0.633.\n"
     ]
    }
   ],
   "source": [
    "X=df[['Pclass', 'SibSp', 'Parch']]\n",
    "kNN.fit(X, y)\n",
    "print(f'Accuracy on training data is {round(kNN.score(X, y), 3)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b617602",
   "metadata": {},
   "source": [
    "### 1e.  Use one-hot encoding\n",
    "to include a binary 'male'  feature made from the 'Sex' feature. (Or include a binary 'female'\n",
    "feature, according to your preference. Using both is unnecessary since either is the logical\n",
    "negation of the other.) That is, train on these features: 'Pclass', 'SibSp', 'Parch', 'male'.\n",
    "- Use pandas's df.join(pd.get_dummies())`.\n",
    "- Report training accuracy as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71d04e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data is 0.744.\n"
     ]
    }
   ],
   "source": [
    "X=df[['Pclass', 'Sex', 'SibSp', 'Parch']]\n",
    "\n",
    "X=X.join(pd.get_dummies(X[\"Sex\"])[\"male\"])\n",
    "X=X.drop([\"Sex\"], axis=1)\n",
    "\n",
    "kNN.fit(X, y)\n",
    "\n",
    "print(f'Accuracy on training data is {round(kNN.score(X, y), 3)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210618af",
   "metadata": {},
   "source": [
    "### 1f. Use data imputation\n",
    "to include an 'age' feature made from 'Age' but replacing each missing value with the median\n",
    "of the non-missing ages. That is, train on these features: 'Pclass', 'SibSp', 'Parch', 'male',\n",
    "'age'.\n",
    "\n",
    "- Report training accuracy as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0753fb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data is 0.861.\n"
     ]
    }
   ],
   "source": [
    "X2 = X.join(df[\"Age\"])\n",
    "X2[\"Age\"] = X2[\"Age\"].fillna(X2[\"Age\"].median())\n",
    "kNN.fit(X2, y)\n",
    "print(f'Accuracy on training data is {round(kNN.score(X2, y), 3)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9050084a",
   "metadata": {},
   "source": [
    "## 2. Explore model fit, overfit, and regularization in the context of multiple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715fc1b2",
   "metadata": {},
   "source": [
    "### 2a. Prepare the data:\n",
    "- Read [http://www.stat.wisc.edu/~jgillett/451/data/mtcars.csv](http://www.stat.wisc.edu/~jgillett/451/data/mtcars.csv) into a DataFrame.\n",
    "- Set a variable `X` to the subset consisting of all columns except `mpg`.\n",
    "- Set a variable `y` to the `mpg` column.\n",
    "- Use `train_test_split()` to split `X` and `y` into `X_train`, `X_test`, `y_train`, and `y_test`.\n",
    "  - Reserve half the data for training and half for testing.\n",
    "  - Use `random_state=0` to get reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbf49fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.read_csv(\"http://www.stat.wisc.edu/~jgillett/451/data/mtcars.csv\")\n",
    "#dff = dff.set_index(\"Unnamed: 0\")\n",
    "X = dff.drop(\"mpg\", axis=1)\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "y = dff[\"mpg\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1b3e11",
   "metadata": {},
   "source": [
    "### 2b. Train three models on the training data and evaluate each on the test data:\n",
    "- `LinearRegression()`\n",
    "- `Lasso()`\n",
    "- `Ridge()`\n",
    "\n",
    "The evaluation consists in displaying MSE$_\\text{train}, $ MSE$_\\text{test}$, and the coefficients $\\mathbf{w}$ for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb40699b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE_tr: 5.443140246024981e-29 \n",
      "MSE_te: 11.198177807346006 \n",
      "Coeffs: [-1.39244595e-02 -7.44628132e-03  4.00323924e-03  7.92716848e-01\n",
      " -3.21854592e+00  1.09825372e+00 -4.82369921e-01  4.70797947e-01\n",
      "  1.49546846e+00 -1.04547895e+00  4.44089210e-16 -3.91445660e-02\n",
      " -2.22044605e-16  0.00000000e+00 -1.65252552e+00  1.06274512e-01\n",
      "  2.60480513e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  6.32319472e-01 -6.87968731e-01  1.02875601e+00  1.03011212e+00\n",
      "  1.40754216e+00  0.00000000e+00 -4.22170331e-01 -2.16463206e-01\n",
      "  0.00000000e+00  1.85342041e-02 -6.61886365e-01  0.00000000e+00\n",
      "  0.00000000e+00  3.87050385e-01  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  2.75586445e+00  0.00000000e+00  0.00000000e+00\n",
      " -3.94677511e+00] \n",
      "\n",
      "MSE_tr: 5.692738046538883 \n",
      "MSE_te: 12.99192397981821 \n",
      "Coeffs: [-0.         -0.03718773 -0.01681757  0.         -0.          0.\n",
      "  0.          0.          0.         -0.84712891  0.          0.\n",
      "  0.          0.         -0.          0.         -0.          0.\n",
      "  0.          0.          0.         -0.          0.          0.\n",
      "  0.          0.         -0.         -0.          0.         -0.\n",
      " -0.          0.          0.         -0.          0.          0.\n",
      "  0.          0.          0.          0.         -0.        ] \n",
      "\n",
      "MSE_tr: 0.6709917611488141 \n",
      "MSE_te: 11.114025642784727 \n",
      "Coeffs: [-2.06501026e-01 -1.59345516e-02  2.59522466e-04  5.11086085e-01\n",
      " -2.23033639e+00  5.81652519e-01 -1.94427836e-01  4.15445997e-01\n",
      "  8.44834172e-01 -1.16621620e+00  0.00000000e+00 -1.17815227e-01\n",
      "  0.00000000e+00  0.00000000e+00 -9.60240342e-01  1.68589209e-01\n",
      "  1.73839917e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  4.67289968e-01 -3.44805207e-01  7.38642031e-01  5.64559505e-01\n",
      "  8.45343912e-01  0.00000000e+00 -3.10036064e-01 -1.88530880e-01\n",
      "  0.00000000e+00 -1.17767647e-01 -4.72028006e-01  0.00000000e+00\n",
      "  0.00000000e+00  1.25419688e-01  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  1.62127783e+00  0.00000000e+00  0.00000000e+00\n",
      " -2.19373869e+00] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [linear_model.LinearRegression(),\n",
    "              linear_model.Lasso(), #sets some coeffs to zero\n",
    "              linear_model.Ridge()]\n",
    "\n",
    "for model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        MSE_train = (1/y_train.size) * np.sum((y_train - model.predict(X_train))**2)\n",
    "        MSE_test = (1/y_test.size)  * np.sum((y_test - model.predict(X_test))**2)\n",
    "        \n",
    "        print(\"MSE_tr:\",MSE_train, \"\\nMSE_te:\",MSE_test, \"\\nCoeffs:\", model.coef_, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523ff587",
   "metadata": {},
   "source": [
    "### 2c. Answer a few questions about the models:\n",
    "- Which one best fits the training data?\n",
    "- Which one best fits the test data?\n",
    "- Which one does feature selection by setting most coefficients to zero?- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c91d00",
   "metadata": {},
   "source": [
    " - The lower the MSE value is the better the models fit is because there is less cumulative error between the actually and predicted y values. For the Linear Regression model the MSE value for the training data is the lowest of the three models.\n",
    " - For the test date the best fit model is the Ridge model since it has the lowerest MSE value.\n",
    " - The Lasso model does feature selection by setting most coefficients to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e59bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
